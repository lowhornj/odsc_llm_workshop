{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94126d5-15cb-4d4e-baa5-96626c0bb217",
   "metadata": {},
   "source": [
    "## Set your OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bce0d-4c23-448f-9764-ab475d122ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9ca6c-7024-4f14-bb67-d6edbd90cab6",
   "metadata": {},
   "source": [
    "## Importing necessary packages\n",
    "\n",
    "- `arxiv` is a really cool package for well, you guessed it-interacting with Arxiv website\n",
    "- `PyPDF2` is a package we will utilise for saving and loading PDFs\n",
    "- `langchain` is a very popular framework for interacting and building on top of LLM(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a19524-73eb-42f1-b6ab-36063070e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import PyPDF2\n",
    "import io\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafc4ed-c58e-40be-82d9-57b7b2295e9b",
   "metadata": {},
   "source": [
    "## Saving to PDF \n",
    "\n",
    "Our main logic is as follows:\n",
    "\n",
    "- Download a PDF from arxiv\n",
    "- Convert it to text\n",
    "- Save the text file\n",
    "\n",
    "Creating embeddings:\n",
    "\n",
    "- We are using chromadb for this excercise\n",
    "- We will create a vector-store from this and return index to langchain queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49252075-8675-4bc8-8ad1-3a9e83b2d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to text\n",
    "def pdf_to_txt(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = ''\n",
    "\n",
    "        # Extract text from each page of the PDF\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to prepare the index for querying\n",
    "def prepare_index(txt_file_path):\n",
    "    loader = TextLoader(txt_file_path)\n",
    "    index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830a36a-42b5-4a9f-8b9e-754ebdb8146a",
   "metadata": {},
   "source": [
    "## Download and save the paper\n",
    "\n",
    "In this part, we take the user query to download and save the paper for us to use `GPT-4` with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ddac1-b245-488f-9584-d5bc4cf8b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ask for Arxiv ID and prepare the index\n",
    "arxiv_id = input(\"Enter Arxiv ID (e.g. 2303.17580): \")\n",
    "search = arxiv.Search(id_list=[arxiv_id])\n",
    "paper = next(search.results())\n",
    "paper.download_pdf(filename=\"downloaded-paper.pdf\")\n",
    "\n",
    "pdf_file_path = 'downloaded-paper.pdf'\n",
    "txt_file_path = 'converted-paper.txt'\n",
    "\n",
    "text = pdf_to_txt(pdf_file_path)\n",
    "\n",
    "# Save the text to a file\n",
    "with io.open(txt_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "# Prepare the index for querying\n",
    "index = prepare_index(txt_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd3420-8850-4c9c-ada4-2b2c1b74ccd9",
   "metadata": {},
   "source": [
    "## Query the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49f464-7dc4-4b93-8c66-60591e76d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop for queries\n",
    "while True:\n",
    "    # Ask for the user's query\n",
    "    user_query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Query the index if it exists\n",
    "    if index:\n",
    "        response = index.query(user_query)\n",
    "        print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cc9bb6-8f2f-4d73-a324-fd659844ec77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef80b27-29c0-44fa-85f3-b8df35c6b62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
